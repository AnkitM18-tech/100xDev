Problem with newrelic
It’s paid and can never be self hosted
They own your data
Very hard to move away from it once it’s ingrained in your system
 

Handy links for today
https://prom.100xdevs.com
https://week-25.100xdevs.com/metrics
https://grafana.100xdevs.com/


Prometheus ->
    Prometheus architecture
        Prometheus is a time series DB. It can monitor your 
            - Processes (node, go, rust…)
            - Hosts

https://prometheus.io/docs/introduction/overview/

1. Multi-dimensional data model with time series data identified by metric name and key/value pairs
Prometheus stores its data in a time series format where each data point consists of:
    - Metric Name: A name that identifies the type of data, e.g., http_requests_total.
    - Labels (Key/Value Pairs): Additional metadata that further identifies and differentiates the time series, e.g., method="GET" and handler="/api". Labels provide a way to add dimensions to the metric data, allowing for flexible and detailed querying and analysis.

2. PromQL, a flexible query language to leverage this dimensionality
PromQL lets you query on top of all your timeseries data.
For example
    - sum(http_requests_total{job="api-server", status="500"})
    - would give you all the http requests that your server handled with status code 500

3. No reliance on distributed storage; single server nodes are autonomous
    - Prometheus is designed to be a standalone, single-node system that does not require external distributed storage solutions. Each Prometheus server node is autonomous, meaning it can independently scrape, store, and query time series data. This design simplifies the system architecture and operational overhead but also means that Prometheus is not inherently horizontally scalable. However sharding techniques can be used to manage larger deployments.

4. Time series collection happens via a pull model over HTTP

Prometheus primarily uses a pull model to collect metrics:
    - Pull Model: Prometheus periodically scrapes metrics from configured targets by making HTTP requests to the /metrics endpoint exposed by the targets. This approach allows Prometheus to control the scraping intervals and retry logic.
    - Targets expose their metrics in a specific format that Prometheus understands, typically using client libraries provided by Prometheus for various languages and environments.

5. Pushing time series is supported via an intermediary gateway
    - While Prometheus generally uses a pull model, it also supports a push model through the Pushgateway:
    - Pushgateway: An intermediary service that allows applications and batch jobs to push metrics to it. The Pushgateway then exposes these metrics for Prometheus to scrape. This is useful for short-lived jobs or services that cannot be scraped reliably.

6. Targets are discovered via service discovery or static configuration

Prometheus supports multiple methods for discovering targets to scrape:
    - Service Discovery: Dynamically discovers targets using various service discovery mechanisms like Kubernetes, Consul, AWS, etc. This allows Prometheus to automatically update its target list as the environment changes.
    - Static Configuration: Manually specifies the list of targets in the configuration file. This is straightforward but less flexible compared to service discovery.

7. Multiple modes of graphing and dashboarding support

Prometheus offers several ways to visualize and interact with the collected metrics:
    - Prometheus UI: A built-in web interface for ad-hoc queries and simple graphing.
    - Grafana: A popular open-source dashboarding tool that integrates well with Prometheus, providing rich visualization and dashboarding capabilities.
    - Alertmanager: A component of the Prometheus ecosystem used to handle alerts generated by Prometheus queries, allowing for complex alerting rules and notification integrations.


If we have processes(nodejs, rust, golang) running on a linux machine, we expose an /metrics endpoint to the prometheus timeseries db. It is hitting this endpoint and fetching the metrics in regular intervals - polling the endpoint and storing and maintaining a database. It will keep on polling and maintaining the metrics in a DB.

We can export all the machine stats by using node exporter library / similar libraries created by prometheus in other processes as well.

Mostly it's a pull based architecture. But if there is a short lived job which runs for sometime and then goes down, in that case we need to push the metrics to the prometheus db via a push gateway.

By default prometheus is built as a pull based architecture. But at times when service discovery is difficult, we need to push the metrics to the prometheus db. For k8s cluster(where pods are getting created and goes down frequently) it has a service discovery process, which can connect to the k8 cluster, hit the right endpoints and fetch the metrics for the pods.

Prometheus UI shows stats using PromQL queries.

We can't horizontally scale prometheus process, we have to create multiple promethues services and shard the data across the services. eg -> node metrcis goes to prom1, golang metrics goes to prom2 likewise.

It is a single node process.

Adding raw metrics
Lets build an express app that exports metrics

Let’s add some hand made metrics to an express app
Initialize a TS project ->
npm init -y
npx tsc --init

Replace rootDir and outDir ->
"rootDir": "./src",
"outDir": "./dist",

Add dependencies ->
npm install express @types/express

Create src/index.ts ->

import express from "express";

const app = express();

app.use(express.json());

app.get("/user", (req, res) => {
    res.send({
        name: "John Doe",
        age: 25,
    });
});

app.post("/user", (req, res) => {
    const user = req.body;
    res.send({
        ...user,
        id: 1,
    });
});

app.listen(3000);

Create a middleware that tracks the total time to handle a request (middleware.ts) ->

import { NextFunction, Request, Response } from "express";

export const middleware = (req: Request, res: Response, next: NextFunction) => {
    const startTime = Date.now();
    next();
    const endTime = Date.now();
    console.log(`Request took ${endTime - startTime}ms`);
}

Add the middleware globally ->
app.use(middleware);

Update package.json to add scripts ->

"scripts": {
    "build": "tsc -b",
    "start": "npm run build && node dist/index.js"
},

Run the application
npm run start

Try to send a request and notice the logs

Add prometheus =>

Lets try putting this data inside prometheus next.

Types of metrics in Prometheus ->

- Counter
    A counter is a cumulative metric that only increases.
    Example: Counting the number of HTTP requests.
- Gauge
    A gauge is a metric that can go up and down. It can be used to measure values that fluctuate, such as the current number of active users or the current memory usage.
    Example: Measuring the current memory usage
- Histogram
    A histogram samples observations (usually things like request durations or response sizes) and counts them in configurable buckets. It also provides a sum of all observed values.
    Example: Measuring the duration of HTTP requests.

Counters =>

Let’s add logic to count the number of requests (throughput) of our application.
 
Install prom-client
    - npm install prom-client

Create a new metrics/requestCount.ts file ->

import { NextFunction, Request, Response } from "express";
import client from "prom-client";

// Create a counter metric
const requestCounter = new client.Counter({
    name: 'http_requests_total',
    help: 'Total number of HTTP requests',
    labelNames: ['method', 'route', 'status_code']
});

export const requestCountMiddleware = (req: Request, res: Response, next: NextFunction) => {
    const startTime = Date.now();

    res.on('finish', () => {
        const endTime = Date.now();
        console.log(`Request took ${endTime - startTime}ms`);

        // Increment request counter
        requestCounter.inc({
            method: req.method,
            route: req.route ? req.route.path : req.path,
            status_code: res.statusCode
        });
    });

    next();
};

Add the middleware to src/index.ts ->
Add a /metrics endpoint to src/index.ts ->

import client from "prom-client";

app.get("/metrics", async (req, res) => {
    const metrics = await client.register.metrics();
    res.set('Content-Type', client.register.contentType);
    res.end(metrics);
})

Start the app
npm run start

----------------------------------------------------
We can't have a million rows for different users data. We can't make the log file very large. Instead user defined buckets can be created for users and that data count can be fetched from metrics endpoint.

eg -> 0.1s -> 1
      5s -> 544 - 1(previous number)

if the request comes and it's response time is less than equal the bucket => we increase the count.(for all the subsequent buckets, that's why we have to minus the previous bucket count to find out the actual no of that specific bucket)

It gets added cumulatively.

-----------------------------------------------------

Better structure ->
Before we proceed, lets aggregate all the metric creation and cleanup logic in the same file.
 
Create a new middleware called metrics/index.ts =>

import { NextFunction, Request, Response } from "express";
import { requestCounter } from "./requestCount";

export const metricsMiddleware = (req: Request, res: Response, next: NextFunction) => {
    const startTime = Date.now();

    res.on('finish', function() {
        const endTime = Date.now();
        console.log(`Request took ${endTime - startTime}ms`);
    
        // Increment request counter
        requestCounter.inc({
            method: req.method,
            route: req.route ? req.route.path : req.path,
            status_code: res.statusCode
        });
    });
    next();
}

Update the metrics/requestCount.ts to export the requestCounter and remove the cleanup logic from here =>

import { NextFunction, Request, Response } from "express";
import client from "prom-client";

// Create a counter metric
export const requestCounter = new client.Counter({
    name: 'http_requests_total',
    help: 'Total number of HTTP requests',
    labelNames: ['method', 'route', 'status_code']
});

Update src/index.ts to use the metricsMiddleware =>

import { metricsMiddleware } from "./metrics";
app.use(metricsMiddleware);

-----------------------------------------------------

Gauge ->
Lets add a gauge metric to our app
Create metrics/activeRequests.ts , export a Gauge from it =>

import client from "prom-client";

export const activeRequestsGauge = new client.Gauge({
    name: 'active_requests',
    help: 'Number of active requests'
});

Import it and update metrics/index.ts =>

import { NextFunction, Request, Response } from "express";
import { requestCounter } from "./requestCount";
import { activeRequestsGauge } from "./activeRequests";

export const cleanupMiddleware = (req: Request, res: Response, next: NextFunction) => {
    const startTime = Date.now();
    activeRequestsGauge.inc();

    res.on('finish', function() {
        const endTime = Date.now();
        console.log(`Request took ${endTime - startTime}ms`);
        
        requestCounter.inc({
            method: req.method,
            route: req.route ? req.route.path : req.path,
            status_code: res.statusCode
        });
        activeRequestsGauge.dec();
    });
}


Add an artificial delay to the get endpoint =>

app.get("/user", async (req, res) => {
    await new Promise((resolve) => setTimeout(resolve, 1000));
    res.send({
        name: "John Doe",
        age: 25,
    });
});

Hit the /user endpoint a few times
Check the metrics

We don't usually track the number of active requests for HTTP servers, but we track in case of websocket servers.

We have to put heavy authentication for this endpoint, so that it is not exposed to the world, and only selected few can only access this endpoint.

Histograms =>

Histograms let you store data in various buckets in a cumulative fashion

Add metrics/requestCount.ts ->

import client from "prom-client";

export const httpRequestDurationMicroseconds = new client.Histogram({
    name: 'http_request_duration_ms',
    help: 'Duration of HTTP requests in ms',
    labelNames: ['method', 'route', 'code'],
    buckets: [0.1, 5, 15, 50, 100, 300, 500, 1000, 3000, 5000] // Define your own buckets here
});

**Buckets here represent the key points you want to measure in your app.
How many people had request handled in 0.1ms, 5ms, 15ms …
This is because prometheus is not a DB, it just exposes all the metrics on an endpoint. That endpoint cant server all the data, and hence prometheus doesnt store the exact values, but how many requests were less than 0.1, 5, 15 …

Update metrics/index.ts ->

import { NextFunction, Request, Response } from "express";
import { requestCounter } from "./requestCount";
import { activeRequestsGauge } from "./activeRequests";
import { httpRequestDurationMicroseconds } from "./requestTime";

export const metricsMiddleware = (req: Request, res: Response, next: NextFunction) => {
    const startTime = Date.now();
    activeRequestsGauge.inc();

    res.on('finish', function() {
        const endTime = Date.now();
        const duration = endTime - startTime;
    
        // Increment request counter
        requestCounter.inc({
            method: req.method,
            route: req.route ? req.route.path : req.path,
            status_code: res.statusCode
        });

        httpRequestDurationMicroseconds.observe({
            method: req.method,
            route: req.route ? req.route.path : req.path,
            code: res.statusCode
        }, duration);

        activeRequestsGauge.dec();
    });
    next();
}

Go to the metrics endpoint

It says =>

There were 0 to /user requests that were handled in less than 0.1ms
There were 0 to /user requests that were handled in less than 5ms
There were 0 to /user requests that were handled in less than 15ms
There were 0 to /user requests that were handled in less than 50ms
There were 0 to /user requests that were handled in less than 100ms
There were 0 to /user requests that were handled in less than 500ms
There were 0 to /user requests that were handled in less than 1000ms
There were 1 to /user requests that were handled in less than 3000ms
There were 1 to /user requests that were handled in less than 5000ms
 
As you can see, this is cumulative.

Number of requests being handled in less than 5000ms = Number of requests being handled in less than 3000ms + Number of requests that took between 3000-5000ms

----------------------------------------------------

Final code ->

https://github.com/100xdevs-cohort-2/week-26-prom
 
With this code, you can run an application and see a bunch of metrics on it in a slightly ugly fashion on an endpoint
You can also try this on your side here - https://prom.100xdevs.com/metrics

 
Actually starting prometheus =>

Let’s start an actual prometheus process that scrapes the linux machine

Until now, we’ve exposed a /metrics endpoint but no one is scraping using it.
Prometheus actually scrapes (pulls) these metrics so you can visualise them over time (time series data)
For that, you need to start prometheus and give it the source of the metrics

Add prometheus.yml ->

global:
  scrape_interval: 15s # How frequently to scrape targets

scrape_configs:
  - job_name: 'nodejs-app'
    static_configs:
      - targets: ['localhost:3000']


Start prometheus locally ->

docker run -p 9090:9090 -v ./prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheus

You can start it w/o docker as well by installing it from source

Try visiting localhost:9090 , you will notice a problem in the status/targets section


The problem is that nothing is running on port 3000 on the prom container, and hence it can't discover our service

Containerising the app =>

Create a Dockerfile for the Node app ->

FROM node:20

# Create app directory
WORKDIR /usr/src/app

# Install app dependencies
COPY package*.json ./

RUN npm install

# Bundle app source
COPY . .

EXPOSE 3000
CMD [ "node", "app.js" ]

Create a docker-compose that starts the nodejs app as well as the prom container

version: '3.8'

services:
  node-app:
    build: ./
    ports:
      - "3000:3000"
    networks:
      - monitoring

  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./:/etc/prometheus
    ports:
      - "9090:9090"
    networks:
      - monitoring

networks:
  monitoring:


Update prometheus.yml =>

global:
  scrape_interval: 15s # How frequently to scrape targets

scrape_configs:
  - job_name: 'nodejs-app'
    static_configs:
      - targets: ['node-app:3000']

Start docker compose
docker-compose up

Try going to http://localhost:9090/
Try executing a query
http_requests_total

Types Of Metrics

Counter -> no of requests, no of exceptions -> value can only go up (increases, never decreases), however the rate can go down (change in number of requests/exceptions i.e slope in the graph)

total number of requests/exceptions => will ony go up
(request/exceptions)/sec => can vary (might go up or down)

We usually store counters -> total number of requests/exceptions, we can always derive the rate of requests/exceptions from the graph.

Gauge -> memory usage, cpu usage => value that can go up or down, we store it in a gauge.









