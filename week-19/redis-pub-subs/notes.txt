What are we learning
    Queues
    Pub subs
    Redis

Usecase - More specifically, we’re learning how we would build a system like leetcode

Part 1 - Queues

Browser -- Submission -- Primary BE ---> Queues --> tasks taken by other worker servers / nodes.(w1,w2,...) They keep on picking tasks one after the other.

Users who want to do long running expensive operations on our machines, we probably want to use an architecture like this. We can upscale or downscale the workers depending on the queue length.

If we execute the code on the primary BE and there is an infinite loop or malicious code then the entire BE CPU will be utilised to run it which may cause the BE to fail. So this execution must be delegated to some worker nodes and timelimit those tasks. It picks things, do execution and respond back. Primary BE puts the tasks on a queue and worker nodes pick up from there one by one. There is a need of queues, to handle requests from concurrent users, so that all requests doesn't overwhelm a single worker server, but by implementing the queue, multiple worker nodes can pick up from the queue slowly and execute one by one. It can guarantee that workers won't get overwhelmed.

Another benefit is that even if the workers are down, the tasks are still in the queue and when the workers are up, the tasks can be picked up one after another.

Also we can autoscale the workers if our queue length increases / decreases. So expenses can be managed by auto scaling aggressively.

Video Transcoding is also a good example here. We upload a video, then it is being pushed to a queue and worker nodes pick up and transcode the video.

examples: RabbitMQ, SQS, Redis etc

Part 2 - Pub Subs

Browser ----- Websocket <-- Pub/Sub <-- Problem Status and info <-- w1

Once the worker picks up the task, the worker needs to tell the browser the Status of the execution.

Once the worker is ready to send the status of the execution, it can send it to a websocket server which is connected to the browser. That is how a worker can talk to the ws server and publish an event to the browser.

- workers can't directly connect to the browser, they are transitive in nature they execute, go down after execution. So they are not exposed to the outer world to connect. They will execute, publish to the pub/sub, and update the status of DB entry.

- so we have a fresh service (node js websocket server) which makes a persistent connection to the browser over which can send the status of the execution.(eg -after execution, whoever has user id 1 send them this status as TLE / Success).

- In the real world we have a fleet of websockets not one, so user can be connected to anyone of the ws servers, so how will the worker know which ws server is connected to the user and how will it send the status, so what it can do is, it can publish the status on to a pub/sub for userId1 and the user can subscribe to that event let's call it userId1 to get the status once it is published. multiple users can subscribe to the same event.

This way the worker can connect to the websocket server, instead of figuring out the actual websocket server to connect to. This is way more efficient.



Polling and long polling is a way to do it. another way is to use pub/subs. => websockets is a better way to do this as the browser won't need to constantly poll the BE for the status.

If we keep on polling the BE, it overwhelms the BE and DB as well. as it keeps on making entries to the database whenever the submission happens. When the worker is done with execution then it updates that status of the entry.(Success, Failure / TLE etc)



Redis =>

Redis is an open-source, in-memory data structure store, used as a database, cache, and message broker
One of the key features of Redis is its ability to keep all data in memory, which allows for high performance and low latency access to data.

Machine =>

CPU ||||  Disk ==> Persistent Log

In memory data structure store =>

Very similar to a DB, only it is in memory. That doesn’t mean it doesn’t have persistence

- RDB (Redis Database File): The RDB persistence performs point-in-time snapshots of your dataset at specified intervals. It creates a compact single-file representation of the entire Redis dataset. The snapshotting process can be configured to run at specified intervals, such as every X minutes if Y keys have changed.

```

save 900 1       # Save the dataset every 900 seconds if at least 1 key changed
save 300 10      # Save the dataset every 300 seconds if at least 10 keys changed
save 60 10000    # Save the dataset every 60 seconds if at least 10000 keys changed

```

- AOF (Append Only File): The AOF persistence logs every write operation received by the server, appending each operation to a file. This file can then be replayed on startup to reconstruct the dataset. 

-------------

We will be using Redis to cache things. Instead of hitting the DB multiple times, we can just fetch one time and cache it in Redis. We can do it in the Node.js process itself like an in-memory store, so on subsequent requests we can return the cached value instead of fetching again.

Redis provides us in-memory storage which makes it faster to retrieve data and serve. It is very fast retrieval, as compared to primary store. Rather than caching in memory of BE , we should cache in Redis. In the real world there might be multiple BE systems, so using Redis we can do distributed caching.(One BE server fetched the data and put in Redis, other BE servers can just check with Redis and respond back to the browser). But if we are storing in any BE in-memory storage then we can't access it from other BEs. We have to store in every BE server's in-memory storage in that way, which is not efficient. We can do distributed caching using Redis which is more efficient.
We can drastically minimize the number of requests to the Database.

If we are storing data in the BE server in-memory (tracks:[]) and BE goes down then data also get lost and again we have to fetch it from DB. But Redis backs the data up in the filesystem, so data won't get lost even if it goes down.
It can recover data from the filesystem.

-----

Starting redis locally

Let’s start redis locally and start using it as a DB
    - docker run --name my-redis -d -p 6379:6379 redis

Connecting to your container
    - docker exec -it container_id /bin/bash

Connecting to the redis cli
    - redis-cli

------

Redis as a DB -->

SET/GET/DEL => set , get , del one key

Setting data
    - SET mykey "Hello" 

Getting data
    - GET mykey

Deleting data
    - DEL mykey

HSET/HGET/HDEL (H = Hash) - set, get, del multiple data to single key (HashMap / Object)

HSET user:100 name "John Doe" email "user@example.com" age "30"
HGET user:100 name
HGET user:100 email

**You should never use redis as your primary database

Very nice video - 
https://www.youtube.com/watch?v=WQ61RL1GpEE

--------

Redis as a queue ->

You can also push to a topic / queue on Redis and other processes can pop from it.

Good example of this is Leetcode submissions that need to be processed asynchronously

Pushing to a queue
    LPUSH problems 1
    LPUSH problems 2

Popping from a queue
    RPOP problems
    RPOP problems 

Blocked pop
    BRPOP problems 0 - block for infinite time, until something gets pushed
    BRPOP problems 30 - block for 30s

The last argument represents the timeout before the blocking should be stopped

---------

Talking to redis via Node.js =>

There are various clients that exist that let you talk to redis via Node.js
https://www.npmjs.com/package/redis
 
Let’s initialize a simple Node.js express server that takes a problem submission (very similar to leetcode) as input and sends it to the queue
Let’s also create a worker service that picks up a problem, waits for 2 seconds and then proceeds to pick the next one

Everytime we put new data in DB, we should clear redis, and put data in DB. So that when the user requests for fresh data, it will again be cached in redis with the new data.

Other scenarios like updating one (redis/postgres) and after that update other one, there are chances that one might succeed and other fails, which will be problematic.So better clear cache and then put data in DB and cache it later in redis when user requests for fresh data.

---

Code =>
    - Create an empty Node.js project
    - Initialize 2 folders inside it
        - express-server
        - worker
Initialize an empty Node.js typescript project in both of them
    - npm init -y
    - npx tsc --init

Install dependencies in express-server
    - npm i express @types/express redis
Install dependencies in worker
    - npm i redis

----

Create index.ts in express-server =>

```

import express from "express";
import { createClient } from "redis";

const app = express();
app.use(express.json());

const client = createClient();
client.on('error', (err) => console.log('Redis Client Error', err));

app.post("/submit", async (req, res) => {
    const problemId = req.body.problemId;
    const code = req.body.code;
    const language = req.body.language;

    try {
        await client.lPush("problems", JSON.stringify({ code, language, problemId }));
        // Store in the database
        res.status(200).send("Submission received and stored.");
    } catch (error) {
        console.error("Redis error:", error);
        res.status(500).send("Failed to store submission.");
    }
});

async function startServer() {
    try {
        await client.connect();
        console.log("Connected to Redis");

        app.listen(3000, () => {
            console.log("Server is running on port 3000");
        });
    } catch (error) {
        console.error("Failed to connect to Redis", error);
    }
}

startServer();
```

----

Create index.ts in worker =>

```

import { createClient } from "redis";
const client = createClient();

async function processSubmission(submission: string) {
    const { problemId, code, language } = JSON.parse(submission);

    console.log(`Processing submission for problemId ${problemId}...`);
    console.log(`Code: ${code}`);
    console.log(`Language: ${language}`);
    // Here you would add your actual processing logic

    // Simulate processing delay
    await new Promise(resolve => setTimeout(resolve, 1000));
    console.log(`Finished processing submission for problemId ${problemId}.`);
}

async function startWorker() {

    try {
        await client.connect();
        console.log("Worker connected to Redis.");

        // Main loop
        while (true) {
            try {
                const submission = await client.brPop("problems", 0);
                // @ts-ignore
                await processSubmission(submission.element);
            } catch (error) {
                console.error("Error processing submission:", error);
                // Implement your error handling logic here. For example, you might want to push
                // the submission back onto the queue or log the error to a file.
            }
        }
    } catch (error) {
        console.error("Failed to connect to Redis", error);
    }
}

startWorker();
```

**
Can u figure out why I had to add a ts-ignore ? Why is the type of submission string?

------------

`BRPOP problems(queue_name) 0` for workers will keep the workers blocked / on hold until there are tasks pushed to the redis queue.
When the tasks are being pushed to the redis queue, they are executed one by one by the workers waiting. When the queue goes empty they will again put on hold until new tasks are being pushed to the redis queue.

If the workers go down, then the tasks will keep on getting piled up in the queue, until the workers are up again, and once up they will execute the tasks again.

Every worker will take one task at a time, and after executing the task, then it will take on another one.

After executing the tasks, the workers will publish the status to pub/subs as well as update the status of the entry in DB.

Redis is single threaded. It can serve a single task at a given time. can't handle parallel requests.

What if the queue pops the task and then the worker goes down without processing? (acknowledged / not acknowledged)
    - we can implement some acknowledgement logic in our code, that if the worker doesn't respond within a given time that the task is done, then we can add the popped task to the queue again, so that the task won't be missed.


In createClient(), it is taking the default redis connection running in docker, but if we have a cloud redis provider then we can put the credentials and url as argument to it, so that we can connect to it.

we can add expiry to the redis cache, or we can clear the cache from redis whenever there is an update, and re-cache it again after updating the db and fetching it from db.

AWS SQS = simple queuing system = redis queue equivalent
AWS SNS = simple notification system = pub/sub equivalent

Depending upon the page we are on, we can subscribe to events and unsubscribe from events.We can check it in network tabs.


-----

Pub subs =>

Publish-subscribe (pub-sub) is a messaging pattern where messages are published to a topic without the knowledge of what or if any subscribers there might be. Similarly, subscribers listen for messages on topics of interest without knowing which publishers are sending them. This decoupling of publishers and subscribers allows for highly scalable and flexible communication systems.

Subscribe to a topic
    - SUBSCRIBE problems_done

Publishing to a topic
    - PUBLISH problems_done "{id: 1, ans: 'TLE'}"


Node.js ----> publish to topic problems ----> PubSub ------> Subscriber 1 , Subscriber 2 listening for messages on topics of interest.

Pub subs in Node.js
 
Let’s update the worker code to publish the final submission from the worker to the redis pub sub

import { createClient } from "redis";
const client = createClient();

async function processSubmission(submission: string) {
    const { problemId, code, language } = JSON.parse(submission);

    console.log(`Processing submission for problemId ${problemId}...`);
    console.log(`Code: ${code}`);
    console.log(`Language: ${language}`);
    // Here you would add your actual processing logic

    // Simulate processing delay
    await new Promise(resolve => setTimeout(resolve, 1000));
    console.log(`Finished processing submission for problemId ${problemId}.`);
    client.publish("problem_done", JSON.stringify({ problemId, status: "TLE" }));
}

async function startWorker() {

    try {
        await client.connect();
        console.log("Worker connected to Redis.");

        // Main loop
        while (true) {
            try {
                const submission = await client.brPop("problems", 0);
                // @ts-ignore
                await processSubmission(submission.element);
            } catch (error) {
                console.error("Error processing submission:", error);
                // Implement your error handling logic here. For example, you might want to push
                // the submission back onto the queue or log the error to a file.
            }
        }
    } catch (error) {
        console.error("Failed to connect to Redis", error);
    }
}

startWorker();

Try subscribing to it from the redis-cli
    - SUBSCRIBE problem_done

Assignment ?
    - Create a websocket server that lets users connect and accepts one message from a user which tells the websocket server the users id (no auth)
    - Make the websocket server subscribe to the pub sub and emit back events to the relevant user 















